# ContextAtlas

ContextAtlas is a general-purpose retrieval-augmented generation (RAG) workspace. It turns your PDFs into a Chroma vector store, adds semantic reranking, and exposes a FastAPI endpoint with a lightweight, modern frontend.

## Highlights

- Precision-grounded responses enforced through a strict JSON prompt with explicit citation blocks and safe fallbacks.
- Hierarchical ingest that enriches chunks with ToC lineage before embedding (BGE family).
- FlagEmbedding reranker on top of the base retriever for better topical alignment.
- Frontend latency telemetry, context audit view, and configurable API endpoint for quick local or remote demos.

## Repository Layout

```
ContextAtlas/
├── main.py                      # FastAPI API surface for the RAG pipeline
├── process_data_hierarchical.py # Hierarchical PDF ingestion to Chroma
├── requirements.txt             # Python dependencies
├── frontend/
│   ├── index.html               # Static console
│   ├── styles.css               # Visual design tokens
│   └── app.js                   # Client logic + fetch layer
├── chroma_db/                   # Generated vector store (ignored)
├── data/                        # Flat PDF drop zone (user supplied)
├── data_toc/                    # PDFs with outlines for hierarchical ingest (user supplied)
├── env.txt                      # Optional local helper for environment variables (ignored)
└── ...
```

> `data/`, `data_toc/`, and any `chroma_db*` directories are created locally by the user and must never be committed. They remain empty in version control.

## Local Data Expectations

- Provide your own PDFs and place them inside `data/` (default) before running the ingestion script. If your PDFs include a reliable table of contents, you may set `DATA_DIR=data_toc` to enable hierarchical ToC enrichment. Without a ToC, ingest still works (just without hierarchy fields).
- The Chroma database lives inside `chroma_db/` (or another path you set) and is generated by `process_data_hierarchical.py`.
- Any sample/output folders are local only and ignored via `.gitignore`.
- Only files with the `.pdf` extension are ingested.
- To rebuild the index from scratch, delete the `chroma_db/` folder and re-run the ingestion script.

## Prerequisites

- Python 3.10 or newer (3.10.12 verified)
- Google Gemini access (e.g., Gemini 1.5 Flash) with an API key
- Windows PowerShell 5.1 or newer for the provided commands

## Setup

1. **Create a virtual environment and install dependencies**

	```powershell
	python -m venv venv
	.\venv\Scripts\Activate.ps1
	pip install --upgrade pip
	pip install -r requirements.txt
	```

2. **Configure environment variables**

	```powershell
	setx GOOGLE_API_KEY "<your-google-genai-key>"
	setx CHROMA_DB_PATH "C:\\path\\to\\chroma_db"          # optional override
	setx CHROMA_COLLECTION "contextatlas_collection"            # optional override
	```

	Restart the shell after running `setx` so the process picks up the new values. For temporary sessions, use `$env:GOOGLE_API_KEY = "..."` instead.

3. **Prepare documents**

	- Place PDFs inside `data/` (default ingest source).
	- Optional: if your PDFs have a good table of contents, place them in `data_toc/` and run with `DATA_DIR=data_toc` to attach hierarchical metadata to chunks.

4. **Build or refresh the vector store**

	```powershell
	python process_data_hierarchical.py
	```

	The script semantically chunks your documents and writes to `chroma_db/`. If `DATA_DIR=data_toc`, it also enriches chunks with ToC-based hierarchy labels.

5. **Run the FastAPI service**

	```powershell
	uvicorn main:app --host 0.0.0.0 --port 8000 --reload
	```

	The server validates access to Chroma on startup. `GET /health` returns `200` when the index and reranker are ready.

6. **Launch the frontend console**

	```powershell
	cd frontend
	python -m http.server 5173
	```

	Visit `http://localhost:5173`. The UI targets `http://localhost:8000` by default; append `?api=https://your-endpoint` to switch targets. The preference is saved in `localStorage`.

## API Reference

- **POST `/query`** – body `{ "query": "...", "top_k": 3 }`. Returns `{ "answer": str, "contexts": list[str] }` with trailing citation block when evidence exists.
- **GET `/health`** – readiness probe. Responds with `503` if embeddings or reranker have not finished loading.

## Development Notes

- `GOOGLE_API_KEY` must be provided through the environment. Secrets are never stored in source.
- Customize defaults with `CHROMA_DB_PATH`, `CHROMA_COLLECTION`, `EMBED_MODEL_NAME`, and `GEMINI_MODEL_NAME`.
- `python -m compileall main.py` offers a quick syntax gate before pushing changes.

## Roadmap Ideas

- Add unit coverage for the retrieval pipeline once mockable paths are available.
- Expose reranker scores and retrieved page labels in the frontend response view.
- Package the API and frontend behind a single ASGI deployment for easier hosting.

This project is built end-to-end by a single contributor and is not affiliated with any hackathon or organization. Use it for any domain.
